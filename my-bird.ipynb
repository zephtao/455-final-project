{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_bird_data(augmentation=0):\n    transform_train = transforms.Compose([\n        transforms.Resize(128),\n        transforms.RandomCrop(128, padding=8, padding_mode='edge'), # Take 128x128 crops from padded images\n        transforms.RandomHorizontalFlip(),    # 50% of time flip image along y-axis\n        transforms.ColorJitter(),\n        transforms.RandomRotation(45),\n        transforms.ToTensor(),\n    ])\n    \n    transform_test = transforms.Compose([\n        transforms.Resize(128),\n        transforms.ToTensor(),\n    ])\n    trainset = torchvision.datasets.ImageFolder(root='/kaggle/input/birds23sp/birds/train', transform=transform_train)\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n\n    testset = torchvision.datasets.ImageFolder(root='/kaggle/input/birds23sp/birds/test', transform=transform_test)\n    testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n    classes = open(\"/kaggle/input/birds23sp/birds/names.txt\").read().strip().split(\"\\n\")\n    class_to_idx = trainset.class_to_idx\n    idx_to_class = {int(v): int(k) for k, v in class_to_idx.items()}\n    idx_to_name = {k: classes[v] for k,v in idx_to_class.items()}\n    return {'train': trainloader, 'test': testloader, 'to_class': idx_to_class, 'to_name':idx_to_name}\n\ndata = get_bird_data()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataiter = iter(data['train'])\nimages, labels = next(dataiter)\nimages = images[:8]\nprint(images.size())\n\ndef imshow(img):\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n# show images\nimshow(torchvision.utils.make_grid(images))\n# print labels\nprint(\"Labels:\" + ', '.join('%9s' % data['to_name'][labels[j].item()] for j in range(8)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(net, dataloader, epochs=1, start_epoch=0, lr=0.01, momentum=0.9, decay=0.0005, \n          verbose=1, print_every=10, state=None, schedule={}, checkpoint_path=None):\n    net.to(device)\n    net.train()\n    losses = []\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=decay)\n\n    # Load previous training state\n    if state:\n        net.load_state_dict(state['net'])\n        optimizer.load_state_dict(state['optimizer'])\n        start_epoch = state['epoch']\n        losses = state['losses']\n\n    # Fast forward lr schedule through already trained epochs\n    for epoch in range(start_epoch):\n        if epoch in schedule:\n            print (\"Learning rate: %f\"% schedule[epoch])\n            for g in optimizer.param_groups:\n                g['lr'] = schedule[epoch]\n\n    for epoch in range(start_epoch, epochs):\n        sum_loss = 0.0\n\n        # Update learning rate when scheduled\n        if epoch in schedule:\n            print (\"Learning rate: %f\"% schedule[epoch])\n            for g in optimizer.param_groups:\n                g['lr'] = schedule[epoch]\n\n        for i, batch in enumerate(dataloader, 0):\n            inputs, labels = batch[0].to(device), batch[1].to(device)\n\n            optimizer.zero_grad()\n\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()  # autograd magic, computes all the partial derivatives\n            optimizer.step() # takes a step in gradient direction\n\n            losses.append(loss.item())\n            sum_loss += loss.item()\n\n            if i % print_every == print_every-1:    # print every 10 mini-batches\n                if verbose:\n                  print('[%d, %5d] loss: %.3f' % (epoch, i + 1, sum_loss / print_every))\n                sum_loss = 0.0\n        if checkpoint_path:\n            state = {'epoch': epoch+1, 'net': net.state_dict(), 'optimizer': optimizer.state_dict(), 'losses': losses}\n            torch.save(state, checkpoint_path + 'checkpoint-%d.pkl'%(epoch+1))\n    return losses","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def accuracy(net, dataloader):\n  net.to(device)\n  net.eval()\n  correct = 0\n  total = 0\n  with torch.no_grad():\n      for batch in dataloader:\n          images, labels = batch[0].to(device), batch[1].to(device)\n          outputs = net(images)\n          _, predicted = torch.max(outputs.data, 1)\n          total += labels.size(0)\n          correct += (predicted == labels).sum().item()\n  return correct/total","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(net, dataloader, ofname):\n    out = open(ofname, 'w')\n    out.write(\"path,class\\n\")\n    net.to(device)\n    net.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for i, (images, labels) in enumerate(dataloader, 0):\n            if i%100 == 0:\n                print(i)\n            images, labels = images.to(device), labels.to(device)\n            outputs = net(images)\n            _, predicted = torch.max(outputs.data, 1)\n            fname, _ = dataloader.dataset.samples[i]\n            out.write(\"test/{},{}\\n\".format(fname.split('/')[-1], data['to_class'][predicted.item()]))\n    out.close()\n\ndef smooth(x, size):\n    return np.convolve(x, np.ones(size)/size, mode='valid')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install timm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Darknet64(nn.Module):\n    def __init__(self):\n        super(Darknet64, self).__init__() # https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n        self.conv1 = nn.Conv2d(3, 16, 3, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(16)\n\n        self.conv2 = nn.Conv2d(16, 32, 3, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(32)\n\n        self.conv3 = nn.Conv2d(32, 64, 3, padding=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(64)\n\n        self.conv4 = nn.Conv2d(64, 128, 3, padding=1, bias=False)\n        self.bn4 = nn.BatchNorm2d(128)\n\n        self.conv5 = nn.Conv2d(128, 256, 3, padding=1, bias=False)\n        self.bn5 = nn.BatchNorm2d(256)\n\n        self.fc1 = nn.Linear(256, 555)\n\n    def forward(self, x):\n        x = F.max_pool2d(F.relu(self.bn1(self.conv1(x))), kernel_size=2, stride=2)\n        x = F.max_pool2d(F.relu(self.bn2(self.conv2(x))), kernel_size=2, stride=2)\n        x = F.max_pool2d(F.relu(self.bn3(self.conv3(x))), kernel_size=2, stride=2)\n        x = F.max_pool2d(F.relu(self.bn4(self.conv4(x))), kernel_size=2, stride=2)\n        x = F.max_pool2d(F.relu(self.bn5(self.conv5(x))), kernel_size=2, stride=2)\n        x = F.adaptive_avg_pool2d(x, 1)\n        x = torch.flatten(x, 1)\n        \n        x = self.fc1(x)\n        return x","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the darknet64 model\ncheckpoints = '/kaggle/working/'\nnet = Darknet64()\nstate = torch.load('/kaggle/working/checkpoint-5.pkl')\nlosses = train(net, data['train'], epochs=5, schedule={0:.1, 5:.01, 15:.001}, checkpoint_path=checkpoints, state=None)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrain_net = Darknet64()\n\n# Load weights from pretrained ImageNet model\nstate = torch.load('/kaggle/input/checkpoints/checkpoint-5.pkl')\npretrain_net.load_state_dict(state['net'], strict=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the accuracy of the darknet64 model\nprint(\"Training accuracy: %f\" % accuracy(net, data['train']))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the resnet18 model and store intermediate results in checkpoints\ncheckpoints = '/kaggle/working/'\nmodel = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\nlosses = train(model, data['train'], epochs=1, lr=.01, print_every=10, checkpoint_path=checkpoints)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the efficientnet_v2_l model and store intermediate results in checkpoints\ncheckpoints = '/kaggle/working/'\nmodel = torchvision.models.efficientnet_v2_l(weights='EfficientNet_V2_L_Weights.DEFAULT').to(device)\nlosses = train(model, data['train'], epochs=20, lr=.007, print_every=10, checkpoint_path=checkpoints)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the training accuracy using the last set of checkpoints\nmodel = torchvision.models.efficientnet_v2_l(weights='EfficientNet_V2_L_Weights.DEFAULT').to(device)\nstate = torch.load(checkpoints + 'checkpoint-20.pkl')\nmodel.load_state_dict(state['net'])\nprint(\"Training accuracy: %f\" % accuracy(model, data['train']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate the csv file with our predictions\npredict(model, data['test'], \"/kaggle/working/\" + \"submissions.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the losses\nplt.title(\"EfficientNet, 20 epochs, learning rate 0.007\")\nplt.ylabel(\"loss\")\nplt.plot(smooth(losses, 50))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}